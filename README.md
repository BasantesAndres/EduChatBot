# ğŸ“š EduChatAgent â€“ Databases Course Intelligent Tutor

**Author:** AndrÃ©s Basantes  
**Course:** Intelligent Agents â€“ Yachay Tech  
**Target Course:** Databases (UC1)

---

## ğŸ§  Project Overview

EduChatAgent is an **LLM-powered educational assistant** specialized in the **Databases** course.  
It answers questions about:

- âœ… **Course logistics** â€“ schedule, evaluation, final project weight  
- âœ… **Theory & concepts** â€“ relational model, SQL, APIs, NoSQL  
- âœ… **Practice** â€“ quiz-style questions and exercises based on course material  
- âœ… **Bibliography** â€“ main books and reference material from the syllabus  

The agent is built using:

- ğŸ§© **LangChain** â€“ prompt templates, chains, memory  
- ğŸ”€ **LangGraph** â€“ graph-based workflow (router + tools + memory)  
- ğŸ§  **Ollama** â€“ open LLM `gemma3:4b` for local inference  
- ğŸ§® **RAG** â€“ Retrieval-Augmented Generation over syllabus, units, quizzes, evaluation and bibliography  
- ğŸ§± **FastAPI** â€“ REST API  
- ğŸ’» **Minimalist Web UI** â€“ HTML/CSS/JS single-page chat interface  

---

## ğŸ¯ Objectives

1. **Design and implement a full LLM agent pipeline**:
   - Environment â†” LLM Reasoning â†” Tools/Actions â†” Output.
2. **Demonstrate LangChain competencies**:
   - Prompt templates, router chain, memory, (sequential) chains.
3. **Demonstrate LangGraph competencies**:
   - Graph with router node, multiple nodes, memory and tools.
4. **Use open-source LLMs**:
   - Local inference with **Ollama `gemma3:4b`**.
5. **Integrate RAG for course grounding**:
   - Syllabus, UC1â€“UC4 contents, quizzes, evaluation scheme, bibliography.
6. **Expose the agent via API + Web UI** for an interactive educational experience.

---

## ğŸ—ï¸ High-Level Architecture

```text
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Raw Course Docs    â”‚
           â”‚  (txt syllabus,     â”‚
           â”‚   UC1â€“UC4, quizzes, â”‚
           â”‚   evaluation, bibl.)â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚  build_rag.py
                     â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ Vector Store   â”‚
             â”‚ (Chroma +      â”‚
             â”‚  MiniLM emb.)  â”‚
             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  course_rag_search()
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LangGraph Workflow                        â”‚
â”‚                                                              â”‚
â”‚  START â†’ input â†’ router â†’ { faq | concept | practice }       â”‚
â”‚                         â”‚          â”‚            â”‚            â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â†’ memory_node â†’ final â†’ END   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Ollama LLM         â”‚
          â”‚  gemma3:4b          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           CLI / FastAPI / Web UI
```

---

## ğŸ“‚ Project Structure

```text
EduChatBot/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ educhat/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py          # LLM configuration (Ollama gemma3:4b, params)
â”‚   â”‚   â”œâ”€â”€ llm_factory.py     # Builds ChatOllama LLM from config
â”‚   â”‚   â”œâ”€â”€ prompts.py         # All prompt templates (router, FAQ, concept, JSON)
â”‚   â”‚   â”œâ”€â”€ chains.py          # LangChain chains (router, FAQ, concept, practice, memory)
â”‚   â”‚   â”œâ”€â”€ tools.py           # RAG tool: course_rag_search()
â”‚   â”‚   â”œâ”€â”€ rag_store.py       # Build/load vector store (Chroma + MiniLM embeddings)
â”‚   â”‚   â”œâ”€â”€ build_rag.py       # CLI to index course docs in data/raw
â”‚   â”‚   â”œâ”€â”€ graph.py           # LangGraph workflow (nodes, state, routing)
â”‚   â”‚   â”œâ”€â”€ cli.py             # Terminal chatbot client
â”‚   â”‚   â”œâ”€â”€ api.py             # FastAPI app exposing POST /chat
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ raw/               # âœ¨ Source text files for RAG
â”‚       â”‚   â”œâ”€â”€ syllabus.txt
â”‚       â”‚   â”œâ”€â”€ uc_contents.txt
â”‚       â”‚   â”œâ”€â”€ Contenido UC1.txt
â”‚       â”‚   â”œâ”€â”€ evaluation.txt
â”‚       â”‚   â”œâ”€â”€ bibliography.txt
â”‚       â”‚   â””â”€â”€ quizzes_*.txt
â”‚       â””â”€â”€ processed/
â”‚           â””â”€â”€ chroma/        # Auto-generated Chroma DB (ignored by git)
â”‚
â”œâ”€â”€ web/
â”‚   â””â”€â”€ index.html             # Minimalist single-page chat UI
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ§© RAG: Retrieval-Augmented Generation

The agent is grounded on the actual content of the Databases course.

### ğŸ“ Data sources (in `src/data/raw/`)

- `syllabus.txt` â€“ official course description, learning outcomes.
- `uc_contents.txt` â€“ UC1â€“UC4 titles and topics:
  - UC1 â€“ Fundamentals and Database Design  
  - UC2 â€“ SQL (DDL, DML, joins, aggregation, functions)  
  - UC3 â€“ APIs for database operations  
  - UC4 â€“ NoSQL databases.
- `Contenido UC1.txt` â€“ detailed UC1 theory and instructor notes.
- `evaluation.txt` â€“ evaluation scheme (percentages, final project weight).
- `bibliography.txt` â€“ main books and references.
- `quizzes_*.txt` â€“ past quiz questions to inspire practice questions.

### ğŸ”§ Building the vector store

RAG is built with:

- **Embeddings:** `sentence-transformers/all-MiniLM-L6-v2`
- **Vector store:** ChromaDB

```bash
# From project root
cd src
python -m educhat.build_rag
```

You should see something like:

```text
Loaded N documents from data/raw
âœ… Vector store built in data/processed/chroma
```

### ğŸ§° RAG tool â€“ `course_rag_search`

In `tools.py`:

- Loads the Chroma vector store.
- Creates a retriever with `k=2` similar chunks.
- Uses `.invoke(query)` (LangChain v0.2+).
- Concatenates the chunks and **truncates** the context (e.g. 800â€“1000 chars) to stay within the LLMâ€™s context window and respond faster.

This tool is used inside the LangGraph nodes (concept and practice) to inject **course-specific context** into the prompts.

---

## ğŸ’¬ Prompt Engineering

All prompts are defined in `prompts.py` using `PromptTemplate`.

### 1. ğŸ§­ Router Prompt

Decides if a question is:

- `"faq"` â€“ schedule, grading, logistics  
- `"concept"` â€“ theory, explanations  
- `"practice"` â€“ exercises, quiz-style questions

The router returns **exactly** one of: `faq`, `concept`, `practice`.

### 2. ğŸ“… FAQ Prompt (Logistics & Evaluation)

- Contains **hard-coded** course logistics:
  - Schedule: e.g. *Monday 17hâ€“19h, Wednesday 16hâ€“19h*
  - Classroom: *PB-A02*
  - Full evaluation scheme:
    - First term: quizzes, project advances, assignments, midterms.
    - Second term: quizzes, advances, assignments, **final project 25%**.
- Explicitly instructs:
  - â€œUse ONLY this information for schedule and grading.â€
  - â€œIf something is not specified, say so.â€

This stops the LLM from hallucinating fake schedules or percentages.

### 3. ğŸ§  Concept Prompt (RAG + Explanation)

- Used for conceptual questions (SQL, ER modeling, normalization, APIs, etc.).
- Receives:
  - `user_input`
  - `history` (conversation)
  - `retrieved_context` (RAG output)
- Instructions:
  - Use **only** retrieved course documents (syllabus, UC contents, quizzes).
  - Explain step by step in simple English.
  - Include small SQL examples when relevant.
  - If the documents donâ€™t contain the answer, explicitly say so.

### 4. ğŸ§¾ JSON Prompt (Structured Output)

- Used to convert a draft answer into a structured JSON object:

```json
{
  "answer": "Full explanation in natural language",
  "key_points": ["Point 1", "Point 2"],
  "references": ["UC1 - Introduction to databases", "Evaluation - final project 25%"]
}
```

This is useful for:

- Post-processing answers.
- Showing structured information.
- Potential future UI features (e.g., bullet points, references section).

### 5. ğŸ§ª Practice Prompt

- Reuses the JSON prompt but oriented to **practice questions**.
- Takes `user_input` and `retrieved_context` (which can be quiz files).
- Asks the LLM to generate quiz-style questions, answers and short explanations.

---

## ğŸ”— LangChain Design

All chains live in `chains.py` and use **`langchain-classic`**:

- `build_memory()` â†’ `ConversationBufferMemory` to keep dialogue context.
- `build_router_chain(llm)` â†’ `LLMChain` with `router_prompt`.
- `build_faq_chain(llm, memory)` â†’ `LLMChain` with FAQ prompt + memory.
- `build_concept_sequential_chain(llm, memory)`:
  - **Version 1 (full):**  
    - First `LLMChain` generates a **draft explanation** from RAG + history.  
    - Second `LLMChain` converts it into structured JSON.
  - **Version 2 (fast):**  
    - Single `LLMChain` that directly produces JSON from RAG + question.
- `build_practice_chain(llm)` â†’ `LLMChain` that outputs JSON with practice questions.

All chains are **LLM-agnostic**: they just receive a `llm` object (which comes from `llm_factory.py`).

---

## ğŸ•¸ï¸ LangGraph Workflow

Defined in `graph.py`.

### ğŸ§© State definition

```python
class EduChatState(TypedDict, total=False):
    user_input: str
    mode: Literal["faq", "concept", "practice"]
    history: str
    retrieved_context: Optional[str]
    draft_answer: Optional[str]
    json_answer: Optional[str]
    final_answer: str
```

### ğŸ§± Nodes

1. `input_node` â€“ pass-through, just sets the initial state.
2. `router_node` â€“ calls `router_chain.invoke(...)` and sets `mode` in the state.
3. `faq_node` â€“ calls `faq_chain` and sets `final_answer`.
4. `concept_node`:
   - Calls `course_rag_search(user_input)`.
   - Calls the concept chain (draft + JSON, or direct JSON).
   - Stores `retrieved_context`, `draft_answer`, `json_answer`, `final_answer`.
5. `practice_node`:
   - Calls `course_rag_search(user_input)`.
   - Calls the practice chain with `user_input`, `retrieved_context`, `draft_answer=""`.
   - Stores `json_answer`, `final_answer`.
6. `memory_node`:
   - Appends the latest turn to `history`:
     - `User: ...`
     - `Agent: ...`
7. `final_node` â€“ no-op, just returns state.

### ğŸ”€ Edges

- `START â†’ input â†’ router`
- `router` has **conditional edges**:
  - `faq` â†’ `faq_node`
  - `concept` â†’ `concept_node`
  - `practice` â†’ `practice_node`
- Each of these flows into:
  - `faq_node â†’ memory_node`
  - `concept_node â†’ memory_node`
  - `practice_node â†’ memory_node`
- Then:
  - `memory_node â†’ final_node â†’ END`

A global `InMemorySaver` checkpoint is used so that **`thread_id` = session id** keeps separate conversations.

---

## ğŸ¤– LLM: Ollama `gemma3:4b`

The project uses an **open-source LLM running locally**, via **Ollama**:

- Model: `gemma3:4b` (or similar small-to-medium model).
- Integration: `langchain-ollama` (`ChatOllama`).
- Configured in:
  - `config.py` â†’ `DEFAULT_CONFIG_LOW_TEMP`
  - `llm_factory.py` â†’ `make_hf_llm` (which actually returns a `ChatOllama` instance).

Example config:

```python
DEFAULT_CONFIG_LOW_TEMP = LLMConfig(
    model_id="gemma3:4b",
    temperature=0.2,
    top_p=0.9,
    top_k=40,
    max_new_tokens=64,  # short answers for speed
)
```

This satisfies the project requirement of using **open LLMs (Ollama)** and allows fully local inference.

---

## ğŸ§ª Parameters & Behavior

Some parameters you can easily tune:

- **Temperature** (`0.2` vs `0.7`):
  - 0.2 â†’ more focused, less creative â†’ ideal for syllabus/evaluation questions.
  - 0.7 â†’ more creative â†’ can be used for brainstorming practice questions.
- **Max new tokens**:
  - Lower (e.g. `64`) â†’ faster, concise.
  - Higher (e.g. `256`) â†’ more detailed but slower.
- **RAG context length**:
  - `MAX_CONTEXT_CHARS` in `tools.py`.
  - Fewer characters = faster, but less context.

You can run small experiments by changing these values and asking a set of 8â€“10 fixed questions, then comparing correctness, verbosity and hallucinations.

---

## ğŸ–¥ï¸ Running the Project

> **Prerequisites:**
> - Python 3.10+  
> - Ollama installed and model `gemma3:4b` pulled  
> - (Optional) Git, VSCode  

### 1ï¸âƒ£ Create virtual environment and install dependencies

From the project root:

```bash
python -m venv .venv

# PowerShell (Windows)
.\.venv\Scripts\Activate.ps1

# Install dependencies
python -m pip install --upgrade pip
python -m pip install -r requirements.txt
```

### 2ï¸âƒ£ Prepare RAG (index course documents)

```bash
cd src
python -m educhat.build_rag
```

You should see:

```text
Loaded N documents from data/raw
âœ… Vector store built in data/processed/chroma
```

### 3ï¸âƒ£ Run the chatbot in the console (CLI)

```bash
cd src
python -m educhat.cli
```

Example interaction:

```text
ğŸ”„ Compiling EduChatAgent graph, please wait...
âœ… EduChatAgent ready.

Session id (e.g. andres): Andres

Type your questions about the DATABASES course.
Type 'exit' to quit.

You: What topics are covered in UC1?

[EduChatAgent] Generating answer, please wait...

EduChatAgent:
{
  "answer": "... detailed explanation ...",
  "key_points": [...],
  "references": ["UC1 - Fundamentals and Database Design"]
}
```

### 4ï¸âƒ£ Start the API (FastAPI)

From `src`:

```bash
uvicorn educhat.api:app --reload
```

- Interactive docs: `http://127.0.0.1:8000/docs`
- Main endpoint: `POST http://127.0.0.1:8000/chat`

Example JSON body:

```json
{
  "session_id": "andres",
  "message": "How much does the final project cost?"
}
```

### 5ï¸âƒ£ Open the Web UI

- File: `web/index.html`
- Just open it in your browser (double click).
- Make sure the API is running at `http://localhost:8000`.

The UI:

- Shows chat bubbles (user + bot).
- Sends messages via `fetch()` to `POST /chat`.
- Indicates status (â€œReadyâ€, â€œThinkingâ€¦â€, network errors).

---

## âœ… How This Meets the Project Rubric

**LangChain Competencies**

- Prompt templates: `prompts.py` (router, FAQ, concept, JSON).
- Chains:
  - `SequentialChain` (concept explanation â†’ JSON) or simplified single-chain mode.
  - Router chain, FAQ chain, practice chain.
- Memory:
  - `ConversationBufferMemory` in `chains.py`.
- Few-shot / structure:
  - Prompt patterns with examples and JSON output format.

**LangGraph Competencies**

- Graph with:
  - Router node (decides faq/concept/practice).
  - At least 4 nodes: input, router, faq_node, concept_node, practice_node, memory_node, final_node.
- State definition: `EduChatState` (TypedDict).
- Tool integration:
  - `course_rag_search()` as a retriever-based tool.
- Memory:
  - Graph-level state (`history`) and checkpointing via `InMemorySaver` + `thread_id`.

**LLM Competency**

- Open-source LLM via **Ollama (gemma3:4b)**.
- Parameter tuning (temperature, top_p, max_new_tokens) easily configurable in `config.py`.
- Observed behavior differences across configurations (for the written report).

**Agent Competency**

- Full pipeline:
  - **Environment**: syllabus + quizzes + evaluation.
  - **LLM Reasoning**: LangChain chains with prompts & memory.
  - **Tools/Actions**: RAG retrieval tool.
  - **Output**: structured JSON + natural language response.
- Evaluation:
  - Test questions from syllabus and old quizzes.
  - Manual error analysis of correct vs. incorrect answers.
- Comparison of strategies:
  - Without RAG vs. with RAG.
  - Single-step vs. two-step (draft + JSON) answers.

---

## ğŸ” Possible Future Work

- Add **authentication** or per-student sessions.
- Store conversation logs in a real database instead of JSONL.
- Add **teacher mode** to generate new quiz questions from UC contents.
- Export answers / explanations as PDF cheat sheets.
- Integrate voice input/output for accessibility.
- Add more advanced evaluation (automatic grading of answers).

---

## ğŸ™Œ Credits

- **Author:** AndrÃ©s Basantes  
- **Advisor / Course:** Intelligent Agents â€“ Databases, Yachay Tech  
- **Technologies:** Python, LangChain, LangGraph, Ollama, FastAPI, HTML/CSS/JS

> _â€œEduChatAgent is not just a chatbot; it is a course-specific assistant that understands the structure, content and evaluation of the Databases course, and helps students practice and clarify concepts in a grounded way.â€_
